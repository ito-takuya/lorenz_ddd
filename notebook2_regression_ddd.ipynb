{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a7e11a",
   "metadata": {},
   "source": [
    "# Tutorial: Data-driven discovery of Lorenz system: Regression\n",
    "\n",
    "#### Author: Taku Ito\n",
    "\n",
    "7/7/2025\n",
    "\n",
    "Reference:\n",
    "\n",
    "Brunton, Steven L., Joshua L. Proctor, and J. Nathan Kutz. “Discovering Governing Equations from Data: Sparse Identification of Nonlinear Dynamical Systems.” PNAS (2015) https://doi.org/10.1073/pnas.1517384113.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636bacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tutorial_ddd\n",
    "import tutorial_ddd.lorenz\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44958e55",
   "metadata": {},
   "source": [
    "#### Experiment: We want to infer the governing differential equations (e.g., $\\dot{x}$, $\\dot{y}$, $\\dot{z}$) from $x$, $y$, and $z$.\n",
    "* So, we want to infer the derivatives using the linear combination of features of $x$, $y$, and $z$.\n",
    "* This requires building a library of candidate nonlinear functions comprised of $x$, $y$, and $z$ (for the Lorenz) system.\n",
    "* For the Lorenz system, we will simplify this library of functions to include $x$, $y$, $z$, and their second order interactions, i.e., $xx$, $xy$, $xz$, etc.\n",
    "\n",
    "Practically, suppose we want to predict $\\dot{x}$, $\\dot{y}$, and $\\dot{z}$. For our regression, we will fit a regression model using higher order polynomials of $x$, $y$, $z$ of up to order 2. In principle, this can be higher.\n",
    "\n",
    "$$\\dot{x} = \\beta_1 x + \\beta_2 y + \\beta_3 z + \\beta_4 x^2 + \\beta_5 xy + \\beta_6 xz + \\beta_7 y^2 + \\beta_8 yz + \\beta_9 z^2 $$\n",
    "\n",
    "We can then analyze the learned coefficients ($\\beta$) to assess how well we can ''discover'' / recover the underlying governing equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b4e8d",
   "metadata": {},
   "source": [
    "#### 2.1: Define some functions for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f964227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### A function to create a basis set of functions for x, y, and z, and the second order interactions (e.g., xy, xx, xz, etc.) \n",
    "def create_func_library(x, y, z):\n",
    "    function_library = []\n",
    "    library_labels = []\n",
    "\n",
    "    # First include the 1st order variables x, y, z\n",
    "    # X \n",
    "    function_library.append(x)\n",
    "    library_labels.append('x')\n",
    "    # Y\n",
    "    function_library.append(y)\n",
    "    library_labels.append('y')\n",
    "    # Z\n",
    "    function_library.append(z)\n",
    "    library_labels.append('z')\n",
    "\n",
    "    #### 2nd order interactions\n",
    "    # X*X\n",
    "    function_library.append(x*x)\n",
    "    library_labels.append('xx')\n",
    "    # X*Y\n",
    "    function_library.append(x*y)\n",
    "    library_labels.append('xy')\n",
    "    # X*Z\n",
    "    function_library.append(x*z)\n",
    "    library_labels.append('xz')\n",
    "    # Y*Y\n",
    "    function_library.append(y*y)\n",
    "    library_labels.append('yy')\n",
    "    # Y*Z\n",
    "    function_library.append(y*z)\n",
    "    library_labels.append('yz')\n",
    "    # Z*Z\n",
    "    function_library.append(z*z)\n",
    "    library_labels.append('zz')\n",
    "\n",
    "    function_library = np.asarray(function_library).T\n",
    "    return function_library, library_labels\n",
    "\n",
    "\n",
    "#### Function to implement a sequential sparse linear regression\n",
    "def sparsifyRegressors(X,y,lmbda=0.01,n=10):\n",
    "    \"\"\"\n",
    "    Define an interative sparse regression model, where certain columns of the function library are set to 0 if they are below a certain value\n",
    "\n",
    "    X = design matrix\n",
    "    y = target variables to predict\n",
    "    lmbda = threshold -- any coefs lower than lmbda will be zeroed out\n",
    "    n = number of sequential iterations to incrementally sparsify coefficients\n",
    "    \"\"\"\n",
    "    Xi = X.copy()\n",
    "    coef = np.linalg.inv(Xi.T @ Xi) @ Xi.T @ y\n",
    "    \n",
    "\n",
    "    # iterate n, zeroing out regressors with low coefs\n",
    "    for _ in range(n):\n",
    "        smallcoefs = np.abs(coef)<lmbda \n",
    "        for col in range(y.shape[1]):\n",
    "            small_idx = smallcoefs[:,col]\n",
    "            coef[small_idx,col] = 0\n",
    "            big_idx = small_idx==False\n",
    "            coef[big_idx,col] = np.linalg.inv(Xi[:,big_idx].T @ Xi[:,big_idx]) @ Xi[:,big_idx].T @ y[:,col]\n",
    "    return coef\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd0f6e",
   "metadata": {},
   "source": [
    "#### 2.2: Run experiment\n",
    "* Simulate Lorenz time series with specified parameters\n",
    "* Compute sparse regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define initial conditions and parameters and simulate\n",
    "initial_conditions = [0.1, 0.0, 0.0]  # Starting point [x, y, z]\n",
    "sigma_val = 10.0\n",
    "rho_val = 28.0\n",
    "beta_val = 8/3\n",
    "delta_t = 0.01\n",
    "total_steps = 20000 # More steps to see the chaotic attractor\n",
    "\n",
    "print(f\"Simulating Lorenz system with initial conditions: {initial_conditions}\")\n",
    "print(f\"Parameters: sigma={sigma_val}, rho={rho_val}, beta={beta_val}\")\n",
    "print(f\"Time step (dt): {delta_t}, Number of steps: {total_steps}\")\n",
    "\n",
    "# Simulate the system\n",
    "lorenz_trajectory, derivatives = tutorial_ddd.lorenz.simulate_lorenz(\n",
    "    initial_conditions,\n",
    "    sigma=sigma_val,\n",
    "    rho=rho_val,\n",
    "    beta=beta_val,\n",
    "    dt=delta_t,\n",
    "    num_steps=total_steps\n",
    ")\n",
    "\n",
    "noise_amplitude = 0 # 1\n",
    "noise = np.random.normal(0,noise_amplitude,lorenz_trajectory.shape)\n",
    "lorenz_trajectory = lorenz_trajectory + noise\n",
    "\n",
    "\n",
    "#### Compute sparse regression to discover equations models\n",
    "x, y, z = lorenz_trajectory[:,0], lorenz_trajectory[:,1], lorenz_trajectory[:,2]\n",
    "function_library, library_labels = create_func_library(x,y,z)\n",
    "\n",
    "y = derivatives\n",
    "X = function_library.copy()\n",
    "coef = sparsifyRegressors(X,y,lmbda=0.001,n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a404ddc5",
   "metadata": {},
   "source": [
    "#### 2.3: Visualize learned coefficients -- do the learned coefficients match the Lorenz system equations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94882a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "ax = sns.heatmap(coef.T,center=0,cmap='seismic')\n",
    "plt.title('Beta coefficients for each variable')\n",
    "ax.invert_yaxis()\n",
    "plt.xticks(np.arange(0.5,len(library_labels)+0.5),library_labels);\n",
    "plt.xlabel('Function library',fontsize=8)\n",
    "plt.yticks(np.arange(0.5,3+0.5),['x','y','z']);\n",
    "plt.ylabel('Target variable',fontsize=8)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e277c05",
   "metadata": {},
   "source": [
    "#### 2.4: Evaluate model fit: Compute Lorenz system using the learned regression model to simulate Lorenz system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0178f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulateEstimatedLorenz(model_coef, x0, y0, z0, num_steps=20000):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    trajectory = []\n",
    "    trajectory.append(np.asarray([x0, y0, z0]))\n",
    "    for _ in range(num_steps-1):\n",
    "        basis_set, func_labels = create_func_library(trajectory[-1][0], trajectory[-1][1], trajectory[-1][2])\n",
    "        dxdt = basis_set @ model_coef\n",
    "        new_val = trajectory[-1] + dxdt\n",
    "        trajectory.append(new_val)\n",
    "    return np.asarray(trajectory)\n",
    "\n",
    "model_trajectory = simulateEstimatedLorenz(coef, initial_conditions[0], initial_conditions[1], initial_conditions[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b667ba5a",
   "metadata": {},
   "source": [
    "#### 2.5: Compare the original Lorenz system with the learned model from a polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(lorenz_trajectory[:, 0], lorenz_trajectory[:, 1], lorenz_trajectory[:, 2], lw=0.5, alpha=0.8, color='black', label='lorenz')\n",
    "ax.plot(model_trajectory[:, 0], model_trajectory[:, 1], model_trajectory[:, 2], lw=0.5, alpha=0.8, label='model reconstruction -- regression')\n",
    "ax.set_xlabel(\"X-axis\")\n",
    "ax.set_ylabel(\"Y-axis\")\n",
    "ax.set_zlabel(\"Z-axis\")\n",
    "ax.set_title(\"Model Reconstruction: Lorenz Attractor\")\n",
    "plt.legend()\n",
    "\n",
    "# You can also plot individual dimensions against time\n",
    "plt.figure(figsize=(12, 3))\n",
    "time_points = np.arange(0, total_steps * delta_t, delta_t)\n",
    "plt.plot(time_points, model_trajectory[:, 0], label='X-model', color=sns.color_palette('Blues')[1])\n",
    "plt.plot(time_points, lorenz_trajectory[:, 0], label='X(t)-original', color=sns.color_palette('Reds')[1])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"X Variables Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "time_points = np.arange(0, total_steps * delta_t, delta_t)\n",
    "plt.plot(time_points, model_trajectory[:, 1], label='Y-model', color=sns.color_palette('Blues')[1])\n",
    "plt.plot(time_points, lorenz_trajectory[:, 1], label='Y(t)-original', color=sns.color_palette('Reds')[1])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Y Variables Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "time_points = np.arange(0, total_steps * delta_t, delta_t)\n",
    "plt.plot(time_points, model_trajectory[:, 2], label='Z-model', color=sns.color_palette('Blues')[1])\n",
    "plt.plot(time_points, lorenz_trajectory[:, 2], label='Z(t)-original', color=sns.color_palette('Reds')[1])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Z Variables Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ddd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
